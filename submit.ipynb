{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4453645",
   "metadata": {
    "papermill": {
     "duration": 0.005856,
     "end_time": "2021-12-16T14:13:31.125307",
     "exception": false,
     "start_time": "2021-12-16T14:13:31.119451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "[Check out the training notebook here](https://www.kaggle.com/ravishah1/cots-faster-rcnn-training-w-tf-2-0-od-api-0-474)\n",
    "\n",
    "[I also took inspiration from this notebook by Khanh](https://www.kaggle.com/khanhlvg/inference-using-efficientdet-d0-model-tensorflow)\n",
    "\n",
    "### General Info\n",
    "\n",
    "This notebook is the training for a faster-rcnn using the TensorFlow Object Detection API. It uses TensorFlow 2.0 API making it eligable for the TensorFlow Performance Prize. It scores a 0.474\n",
    "\n",
    "The Model I trained was a Faster-RCNN with a Resnet-101 feature extractor. I applied a few augmentations, used a momentum optimizer, and split with a group k-fold on sequence. For more details, see the training notebook linked at the top.\n",
    "\n",
    "I predict with a dataset with weights generated from a notebook identical to the training notebook above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c3dd41a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-16T14:13:31.141414Z",
     "iopub.status.busy": "2021-12-16T14:13:31.139658Z",
     "iopub.status.idle": "2021-12-16T14:13:35.260495Z",
     "shell.execute_reply": "2021-12-16T14:13:35.259412Z"
    },
    "papermill": {
     "duration": 4.130113,
     "end_time": "2021-12-16T14:13:35.260669",
     "exception": false,
     "start_time": "2021-12-16T14:13:31.130556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Import the library that is used to submit the prediction result.\n",
    "INPUT_DIR = '../input/tensorflow-great-barrier-reef/'\n",
    "sys.path.insert(0, INPUT_DIR)\n",
    "import greatbarrierreef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db79d671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-16T14:13:35.280064Z",
     "iopub.status.busy": "2021-12-16T14:13:35.279182Z",
     "iopub.status.idle": "2021-12-16T14:13:56.339610Z",
     "shell.execute_reply": "2021-12-16T14:13:56.338955Z"
    },
    "papermill": {
     "duration": 21.07246,
     "end_time": "2021-12-16T14:13:56.339787",
     "exception": false,
     "start_time": "2021-12-16T14:13:35.267327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 14:13:37.089428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 14:13:37.180903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 14:13:37.181653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 14:13:37.182793: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-16 14:13:37.183572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 14:13:37.184241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 14:13:37.184832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 14:13:39.019561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 14:13:39.020491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 14:13:39.021206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 14:13:39.021848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 21.05643343925476s\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = '../input/cots-fasterrcnn-tfod-api-weights/cots_faster_rcnn_resnet101'\n",
    "start_time = time.time()\n",
    "tf.keras.backend.clear_session()\n",
    "detect_fn_tf_odt = tf.saved_model.load(os.path.join(os.path.join(MODEL_DIR, 'output'), 'saved_model'))\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Elapsed time: ' + str(elapsed_time) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee22b1ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-16T14:13:56.359100Z",
     "iopub.status.busy": "2021-12-16T14:13:56.358231Z",
     "iopub.status.idle": "2021-12-16T14:13:56.360033Z",
     "shell.execute_reply": "2021-12-16T14:13:56.360479Z"
    },
    "papermill": {
     "duration": 0.013825,
     "end_time": "2021-12-16T14:13:56.360650",
     "exception": false,
     "start_time": "2021-12-16T14:13:56.346825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" These functions are not currently being used \"\"\"\n",
    "\n",
    "def RecoverHE(sceneRadiance):\n",
    "    for i in range(3):\n",
    "        sceneRadiance[:, :, i] =  cv2.equalizeHist(sceneRadiance[:, :, i])\n",
    "    return sceneRadiance\n",
    "\n",
    "def apply_HE(img_path: str):\n",
    "    img = cv2.imread(img_path)\n",
    "    sceneRadiance = RecoverHE(img)\n",
    "    return sceneRadiance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06631952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-16T14:13:56.380088Z",
     "iopub.status.busy": "2021-12-16T14:13:56.379169Z",
     "iopub.status.idle": "2021-12-16T14:13:56.381423Z",
     "shell.execute_reply": "2021-12-16T14:13:56.381007Z"
    },
    "papermill": {
     "duration": 0.014887,
     "end_time": "2021-12-16T14:13:56.381546",
     "exception": false,
     "start_time": "2021-12-16T14:13:56.366659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "    path: a file path (this can be local or on colossus)\n",
    "\n",
    "    Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    #image = Image.fromarray(apply_HE(path))\n",
    "    \n",
    "    img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "    image = Image.open(io.BytesIO(img_data))\n",
    "    (im_width, im_height) = image.size\n",
    "    \n",
    "    return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def detect(image_np):\n",
    "    \"\"\"Detect COTS from a given numpy image.\"\"\"\n",
    "\n",
    "    input_tensor = np.expand_dims(image_np, 0)\n",
    "    start_time = time.time()\n",
    "    detections = detect_fn_tf_odt(input_tensor)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd52a1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-16T14:13:56.397646Z",
     "iopub.status.busy": "2021-12-16T14:13:56.396862Z",
     "iopub.status.idle": "2021-12-16T14:13:56.401559Z",
     "shell.execute_reply": "2021-12-16T14:13:56.401117Z"
    },
    "papermill": {
     "duration": 0.01402,
     "end_time": "2021-12-16T14:13:56.401671",
     "exception": false,
     "start_time": "2021-12-16T14:13:56.387651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = greatbarrierreef.make_env()   # initialize the environment\n",
    "iter_test = env.iter_test()    # an iterator which loops over the test set and sample submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7080b214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-16T14:13:56.423622Z",
     "iopub.status.busy": "2021-12-16T14:13:56.423055Z",
     "iopub.status.idle": "2021-12-16T14:14:05.659058Z",
     "shell.execute_reply": "2021-12-16T14:14:05.657728Z"
    },
    "papermill": {
     "duration": 9.251548,
     "end_time": "2021-12-16T14:14:05.659289",
     "exception": false,
     "start_time": "2021-12-16T14:13:56.407741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 14:13:56.873049: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-16 14:13:59.313670: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      "Prediction: \n",
      "Prediction: \n"
     ]
    }
   ],
   "source": [
    "DETECTION_THRESHOLD = 0.50\n",
    "\n",
    "submission_dict = {\n",
    "    'id': [],\n",
    "    'prediction_string': [],\n",
    "}\n",
    "\n",
    "for (image_np, sample_prediction_df) in iter_test:\n",
    "    height, width, _ = image_np.shape\n",
    "    \n",
    "    # Run object detection using the TensorFlow model.\n",
    "    detections = detect(image_np)\n",
    "    \n",
    "    # Parse the detection result and generate a prediction string.\n",
    "    num_detections = detections['num_detections'][0].numpy().astype(np.int32)\n",
    "    predictions = []\n",
    "    for index in range(num_detections):\n",
    "        score = detections['detection_scores'][0][index].numpy()\n",
    "        if score < DETECTION_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        bbox = detections['detection_boxes'][0][index].numpy()\n",
    "        y_min = int(bbox[0] * height)\n",
    "        x_min = int(bbox[1] * width)\n",
    "        y_max = int(bbox[2] * height)\n",
    "        x_max = int(bbox[3] * width)\n",
    "        \n",
    "        bbox_width = x_max - x_min\n",
    "        bbox_height = y_max - y_min\n",
    "        \n",
    "        predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n",
    "    \n",
    "    # Generate the submission data.\n",
    "    prediction_str = ' '.join(predictions)\n",
    "    sample_prediction_df['annotations'] = prediction_str\n",
    "    env.predict(sample_prediction_df)\n",
    "\n",
    "    print('Prediction:', prediction_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.30652,
   "end_time": "2021-12-16T14:14:09.026669",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-16T14:13:22.720149",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
